H2SL (Human to Structured Language) provides a framework for 
realtime natural langugage symbol grounding in the context of 
understanding robot instructions.   

The H2SL project was originally started at the Massachusetts 
Institute of Technology in 2014 by Thomas M. Howard and Matthew R. Walter.
The original codebase was copyrighted by the Massachusetts 
Institute of Technology in 2014. The new codebase has been 
rewritten by researchers from the University of Rochester,
Toyota Technological Institute at Chicago, and the Massachusetts
Institute of Technology. This research was supported by partial
support from the U.S. Army Research Laboratory under the Robotics
Collaborative Technology Alliance, Cooperative Agreement W911NF-10-2-0016,
National Science Foundation National Robotics Initiative Awards #1427547,
#1637813, and #1638072, and an Early Career Faculty grant from NASA’s
Space Technology Research Grants Program. Contributors to this project
include:

Derya Aksaray
Jacob Arkin
Rohan Paul
Benned Hedegaard
Thomas Howard
Siddharth Patki
Joshua Rosser
Matthew Walter

The aforementioned contributors are referred to as the "H2SL Developers"
in the Doxygen documentation throughout this software repository.

This program is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation; either version 2 of the License, or (at
your option) any later version.

This program is distributed in the hope that it will be useful, but
WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program; if not, see
<http://www.gnu.org/licenses/gpl-2.0.html> or write to the Free
Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
02110-1301, USA.

OVERVIEW

H2SL provides a set of base classes for developing a natural language
symbol grounding inferface.  Example symbols, features, and data is 
provided, but is not intended to serve as a drop-in natural language
interface for robotic system.  To adapt to new applications, one can
replace the symbols, features, and examples with those that are 
relevant to your system and domain.  The probablistic graphical models
included in this project are based on the Distributed Correspondence 
Graph (DCG). For more details about variations of DCGs, please refer
to the following papers and articles:

T.M Howard, S. Tellex, and N. Roy. A natural language planner 
interface for mobile manipulators. In Proceedings of the IEEE 
International Conference on Robotics and Automation, pages 6652–6659. 
IEEE, May 2014.

O. Propp, I. Chung, M.R. Walter, and T.M. Howard.  On the performance 
of hierarchical distributed correspondence graphs for efficient 
symbol grounding of robot instructions. In Proceedings of the 2015 
IEEE/RSJ International Conference on Intelligent Robots and Systems, 
October 2015.

R. Paul, J. Arkin, N. Roy, and T.M. Howard. Effcient grounding of 
abstract spatial concepts for natural language interaction with robot 
manipulators. In Proceedings of the 2016 Robotics: Science and Systems 
Conference, June 2016.

Examples of applications of this framework to various problems in 
natural language symbol grounding of robot instructions include 
inferring LTL from language, assistive robotics, inferring maps and
behaviors, expressing homotopy constraints and multi-modal interactions 
with human-robot teams.  For more details of these applications, 
please refer to the following papers and articles:

F. Duvallet, M.R. Walter, T.M. Howard, S. Hemachandra, J. Oh, S. Teller, 
N. Roy, and A. Stentz. A probabilistic framework for inferring maps 
and behaviors from natural language. In Proceedings of the 14th 
International Symposium on Experimental Robotics, July 2014.

S. Hemachandra, F. Duvallet, T.M. Howard, N. Roy, A. Stentz, and 
M.R. Walter. Learning models for following natural language directions 
in unknown environments. In Proceedings of the IEEE International 
Conference on Robotics and Automation. IEEE, May 2015.

D. Yi, T.M. Howard, K. Seppi, and M. Goodrich. Expressing homotopic 
requirements for mobile robot navigation through natural language 
instructions. In Proceedings of the 2016 IEEE/RSJ International 
Conference on Intelligent Robots and Systems, October 2016.

J. Oh, T.M. Howard, M. Walter, D. Barber, M. Zhu, S. Park, A. Suppe, 
L. Navarro-Serment, F. Duvallet, A. Boularias, O. Romero, J. Vinokrov, 
T. Keegan, R. Dean, C. Lennon, B. Bodt, M. Childers, J. Shi, K. Daniilidis, 
N. Roy, C. Lebiere, M. Hebert, and A. Stentz. Integrated intelligence for 
human-robot teams. In Proceedings of the 2016 International Symposium on 
Experimental Robotics, October 2016.

A. Boteanu, J. Arkin, T.M. Howard, and H. Kress-Gazit. A model for 
verifable grounding and execution of complex language instructions. In
Proceedings of the 2016 IEEE/RSJ International Conference on Intelligent 
Robots and Systems, October 2016.

A. Broad, J. Arkin, N. Ratliff, T. M. Howard, and B. Argall. Real-time 
natural language corrections for assistive robotic manipulators. 
International Journal of Robotics Research, 36(5-7):684–698, May 2017.

J. Arkin, M. Walter, A. Boteanu, M. Napoli, H. Biggie, H. Kress-Gazit, 
and T.M. Howard. Contextual awareness: Understanding monologic natural 
language instructions for autonomous robots.  In Proceedings of the IEEE
International Symposium on Robot and Human Interactive Communication, 
August 2017.

